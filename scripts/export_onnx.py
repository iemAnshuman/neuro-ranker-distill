import argparse
import torch
import onnx
import sys
import os

# --- Start of Fix ---
# Add the project's root directory to the Python path
# This allows the script to find the 'src' module
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
sys.path.insert(0, project_root)
# --- End of Fix ---

from src.neuro_ranker.trainer_student import BiEncoder

p = argparse.ArgumentParser()
p.add_argument("--ckpt", required=True)
p.add_argument("--model_name", default="sentence-transformers/all-MiniLM-L6-v2")
p.add_argument("--onnx", required=True)
args = p.parse_args()

# Create the output directory if it doesn't exist
os.makedirs(os.path.dirname(args.onnx), exist_ok=True)

ckpt = torch.load(args.ckpt, map_location="cpu")
model = BiEncoder(args.model_name)
model.load_state_dict(ckpt["model"])
model.eval()

# Export encoder that maps input_ids, attention_mask â†’ pooled vector
dummy_ids = torch.randint(0, 100, (1, 256), dtype=torch.long)
dummy_attn = torch.ones_like(dummy_ids)

torch.onnx.export(
    model.encoder,
    (dummy_ids, dummy_attn),
    args.onnx,
    input_names=["input_ids", "attention_mask"],
    output_names=["last_hidden_state", "pooler_output"],
    opset_version=17,
    dynamic_axes={
        "input_ids": {0: "batch", 1: "seq"},
        "attention_mask": {0: "batch", 1: "seq"},
    },
)
print("Exported to", args.onnx)
